{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sql\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pycountry\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_engine = sql.create_engine('postgresql:///metadb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute interference rates for 2019\n",
    "\n",
    "First, we find all measurements that started in the year 2019. Because the measurement table doesn't associate each measurement with a country code, we join each measurement with its report (in the report table), and group the results by country code. The columns are:\n",
    "- country_code\n",
    "- num_confirmed_interference: number of confirmed incidents / country\n",
    "- num_anomaly: number of anomalous incidents / country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_filename = \"interference_rates_2019.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_2019 = pd.read_sql_query(\"\"\"select probe_cc as country_code, \n",
    "    count(case when confirmed then 1 end) as num_confirmed_interference,\n",
    "    count(case when anomaly then 1 end) as num_anomaly\n",
    "    count(case when not confirmed then 1 end) as num_no_confirmed_interference\n",
    "    from (select * from measurement where to_char(measurement.measurement_start_time, 'YYYY') = '2019') meas\n",
    "    left join (select * from report where to_char(measurement.measurement_start_time, 'YYYY') = '2019') rep\n",
    "    on meas.report_no = rep.report_no group by probe_cc\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the query results intermediately to a csv in case kernel dies\n",
    "counts_2019.write_csv(rates_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_2019 = pd.read_csv(rates_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're missing the strict and loose rate columns per country. Note that we calculate <b>strict rate</b> over a date range as:\n",
    "$$\\frac{\\text{number of confirmed events}}{\\text{total number of events}}$$\n",
    "Similarly, we calculate <b>loose rate</b> as:\n",
    "$$\\frac{\\text{number of confirmed events + number of anomalous events}}{\\text{total number of events}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_2019[\"strict_rate\"] = counts_2019[\"num_confirmed_interference\"] / (counts_2019[\"num_confirmed_interference\"] + counts_2019[\"num_no_confirmed_interference\"])\n",
    "counts_2019[\"loose_rate\"] = (counts_2019[\"num_confirmed_interference\"] + counts_2019[\"num_anomaly\"]) / (counts_2019[\"num_confirmed_interference\"] + counts_2019[\"num_no_confirmed_interference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the intermediate query results with the final table \n",
    "counts_2019.write_csv(rates_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which countries have the highest strict rates over 2019?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_2019.sort_values(by = \"strict_rate\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest loose rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_2019.sort_values(by = \"loose_rate\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tables aren't very readable when it comes to comparing different country rates, so let's make some chloropleth maps to compare them more visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue = lower interference rate, red = higher interference rate\n",
    "blured_color_scheme = px.colors.diverging.RdBu[::-1]\n",
    "\n",
    "countries = {}\n",
    "for country in pycountry.countries:\n",
    "    countries[country.alpha_2] = country.alpha_3\n",
    "    \n",
    "counts_2019['iso_alpha3'] = counts_2019['country_code'].apply(lambda x: countries[x] if x in countries else None)\n",
    "\n",
    "map_rates_2019 = new_rates_2019.copy()\n",
    "map_rates_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 map for strict rate\n",
    "fig = px.choropleth(map_rates_2019,\n",
    "                    title = \"Rate of Confirmed Network Interference Events by Country (2019)\",\n",
    "                    locations = \"iso_alpha3\",\n",
    "                    color = \"Strict Rate\", # strict_rate is a column of new_rates_2019\n",
    "                    hover_name = \"country_code\", # column to add to hover information\n",
    "                    color_continuous_scale = blured_color_scheme)\n",
    "\n",
    "fig.update_layout(\n",
    "    title = {\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 map for loose rate\n",
    "fig = px.choropleth(map_rates_2019, locations = \"iso_alpha3\",\n",
    "                    title = \"Rate of Confirmed or Anomalous Network Interference Events by Country (2019)\",\n",
    "                    color = \"Loose Rate\", # loose_rate is a column of new_rates_2019    \n",
    "                    hover_name = \"country_code\", # column to add to hover information\n",
    "                    color_continuous_scale = blured_color_scheme)\n",
    "\n",
    "fig.update_layout(\n",
    "    title = {\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the strict rates map, the most interesting countries are Saudi Arabia, Iran, Russia, Romania, and India in order of decreasing rate.\n",
    "\n",
    "From the loose rates map, the 5 countries with the highest rates are Ukraine, Iran, Russia, China, and India.\n",
    "\n",
    "For both strict and loose rates, we'll use the U.S. as a basis for comparison out of familiarity with national events. Let's take a closer look at how both types of interference rates changed by day to get to their final rankings on 12/30/19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interference rates by day\n",
    "\n",
    "To keep track of how the interference rates change by day, we need to cumulatively sum the number of confirmed, anomalous (and not confirmed) events, grouping by day and country. For example, the cumulative_num_anomaly value for some day $x$ should be the <i>sum</i> of the number of anomalous events for every day in the date range up to and including $x$ for a specific country. Our final table should have the columns below:\n",
    "- country_code\n",
    "- date\n",
    "- cumulative_num_anomaly\n",
    "- cumulative_num_confirmed\n",
    "- cumulative_num_not_confirmed\n",
    "- cumulative_strict_rate\n",
    "- cumulative_loose_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_rates_filename = \"interference_rates_by_day_2019.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_rates_2019 = pd.read_sql_query(\"\"\"select\n",
    "            probe_cc,\n",
    "            date,\n",
    "            sum(day_rates.num_anomaly) as cumulative_num_anomaly,\n",
    "            sum(day_rates.num_confirmed) as cumulative_num_confirmed,\n",
    "            sum(day_rates.num_not_confirmed) as cumulative_num_not_confirmed\n",
    "        from (select\n",
    "            probe_cc as country_code,\n",
    "            to_char(measurement.measurement_start_time, 'YYYY') as date,\n",
    "            count(case when confirmed then 1 end) as num_confirmed,\n",
    "            count(case when anomaly then 1 end) as num_anomaly\n",
    "            count(case when not confirmed then 1 end) as num_not_confirmed\n",
    "        from (select * from measurement where to_char(measurement.measurement_start_time, 'YYYY') = '2019') meas\n",
    "        left join (select * from report where to_char(measurement.measurement_start_time, 'YYYY') = '2019') rep\n",
    "        on meas.report_no = rep.report_no group by probe_cc, to_char(measurement.measurement_start_time, 'YYYY')) day_rates\n",
    "        where date <= day_rates.date\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirmed and anomalous domains by country\n",
    "\n",
    "-- focus on China, Russia, and India, showing how to make the word clouds and going into how the domains that pop up are associated with real-world events / legislation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
